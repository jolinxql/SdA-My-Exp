{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://deeplearning.net/tutorial/SdA.html  \n",
    "http://deeplearning.net/tutorial/code/SdA.py\n",
    "\n",
    "\n",
    "os.path.split(__file__)[1] -->  \n",
    "os.path.split(os.path.realpath('__file__'))[1]\n",
    "\n",
    "## Stacked denoising auto-encoder class (SdA)\n",
    "\n",
    "A stacked denoising autoencoder model is obtained by stacking several dAs. The hidden layer of the dA at layer `i` becomes the input of the dA at layer `i+1`. The first layer dA gets as input the input of the SdA, and the hidden layer of the last dA represents the output. \n",
    "\n",
    " - **Note that after pretraining, the SdA is dealt with as a normal MLP, the dAs are only used to initialize the weights.**\n",
    "\n",
    "## stacked denoising auto-encoders (SdA) using Theano.\n",
    "\n",
    " Denoising autoencoders are the building blocks for SdA.\n",
    " \n",
    " - **Note: go through all pretraining epochs for one layer before to to the next layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import timeit\n",
    "\n",
    "import numpy\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from theano.tensor.shared_randomstreams import RandomStreams\n",
    "\n",
    "import six.moves.cPickle as pickle\n",
    "from logistic_sgd import LogisticRegression, load_data\n",
    "from mlp import HiddenLayer\n",
    "from dA import dA\n",
    "\n",
    "class SdA(object):\n",
    "    \"\"\"Stacked denoising auto-encoder class (SdA)\n",
    "\n",
    "    A stacked denoising autoencoder model is obtained by stacking several\n",
    "    dAs. The hidden layer of the dA at layer `i` becomes the input of\n",
    "    the dA at layer `i+1`. The first layer dA gets as input the input of\n",
    "    the SdA, and the hidden layer of the last dA represents the output.\n",
    "    Note that after pretraining, the SdA is dealt with as a normal MLP,\n",
    "    the dAs are only used to initialize the weights.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        numpy_rng,\n",
    "        theano_rng=None,\n",
    "        n_ins=784,\n",
    "        hidden_layers_sizes=[500, 500],\n",
    "        n_outs=10,\n",
    "        corruption_levels=[0.1, 0.1]\n",
    "    ):\n",
    "        self.sigmoid_layers = []\n",
    "        self.dA_layers = []\n",
    "        self.params = []\n",
    "        self.n_layers = len(hidden_layers_sizes)\n",
    "\n",
    "        assert self.n_layers > 0\n",
    "\n",
    "        if not theano_rng:\n",
    "            theano_rng = RandomStreams(numpy_rng.randint(2 ** 30))\n",
    "        # allocate symbolic variables for the data\n",
    "        self.x = T.matrix('x')  # the data is presented as rasterized images\n",
    "        self.y = T.ivector('y')  # the labels are presented as 1D vector of\n",
    "                                 # [int] labels\n",
    "            \n",
    "        # The SdA is an MLP, for which all weights of intermediate layers\n",
    "        # are shared with a different denoising autoencoders\n",
    "        # We will first construct the SdA as a deep multilayer perceptron,\n",
    "        # and when constructing each sigmoidal layer we also construct a\n",
    "        # denoising autoencoder that shares weights with that layer\n",
    "        # During pretraining we will train these autoencoders (which will\n",
    "        # lead to chainging the weights of the MLP as well)\n",
    "        # During finetunining we will finish training the SdA by doing\n",
    "        # stochastich gradient descent on the MLP\n",
    "        \n",
    "        for i in range(self.n_layers):\n",
    "            # construct the sigmoidal layer\n",
    "            \n",
    "            # the size of the input is either the number of hidden units of\n",
    "            # the layer below or the input size if we are one the first layer\n",
    "            if i==0:\n",
    "                input_size=n_ins\n",
    "            else:\n",
    "                input_size=hidden_layers_sizes[i-1]\n",
    "            \n",
    "            # the input to this layer is either the activation of the hidden\n",
    "            # layer below or the input of the SdA if you r on the first layer\n",
    "            if i==0:\n",
    "                layer_input=self.x\n",
    "            else:\n",
    "                layer_input=self.sigmoid_layers[i-1].output\n",
    "                \n",
    "            sigmoid_layer=HiddenLayer(rng=numpy_rng,input=layer_input,\n",
    "                                      n_in=input_size,\n",
    "                                      n_out=hidden_layers_sizes[i],\n",
    "                                      activation=T.nnet.sigmoid)\n",
    "            \n",
    "            self.sigmoid_layers.append(sigmoid_layer)\n",
    "            # its arguably a philosophical question...\n",
    "            # but we are going to only declare that the parameters of the\n",
    "            # sigmoid_layers are parameters of the StackedDAA\n",
    "            # the visible biases in the dA are parameters of those\n",
    "            # dA, but not the SdA\n",
    "            self.params.extend(sigmoid_layer.params)\n",
    "            \n",
    "            # Construct a denoising autoencoder that shared weights \n",
    "            # with this layers\n",
    "            dA_layer = dA(numpy_rng=numpy_rng,\n",
    "                          theano_rng=theano_rng,\n",
    "                          input=layer_input,\n",
    "                          n_visible=input_size,\n",
    "                          n_hidden=hidden_layers_sizes[i],\n",
    "                          W=sigmoid_layer.W,\n",
    "                          bhid=sigmoid_layer.b)\n",
    "            self.dA_layers.append(dA_layer)\n",
    "            \n",
    "        # We now need to add a logistic layer on top of the MLP\n",
    "        self.logLayer = LogisticRegression(\n",
    "            input=self.sigmoid_layers[-1].output,\n",
    "            n_in=hidden_layers_sizes[-1],\n",
    "            n_out=n_outs\n",
    "        )\n",
    "        \n",
    "        self.params.extend(self.logLayer.params)\n",
    "        \n",
    "        # construct a function that implements one step of finetunining\n",
    "        # compute the cost for second phase of training,\n",
    "        # defined as the negative log likelihood\n",
    "        self.finetune_cost = self.logLayer.negative_log_likelihood(self.y)\n",
    "        # compute the gradients with respect to the model parameters\n",
    "        # symbolic variable that points to the number of errors made on the\n",
    "        # minibatch given by self.x and self.y\n",
    "        self.errors = self.logLayer.errors(self.y)\n",
    "    \n",
    "    def pretraining_functions(self, train_set_x, batch_size):\n",
    "        ''' Generates a list of functions, each of them implementing one\n",
    "        step in trainnig the dA corresponding to the layer with same index.\n",
    "        The function will require as input the minibatch index, and to train\n",
    "        a dA you just need to iterate, calling the corresponding function on\n",
    "        all minibatch indexes.\n",
    "        '''\n",
    "        \n",
    "        # index to a [mini]batch\n",
    "        index=T.lscalar('index')\n",
    "        corruption_level=T.scalar('corruption')\n",
    "        learning_rate=T.scalar('lr')\n",
    "        \n",
    "        # begining of a batch, given index\n",
    "        batch_begin=index*batch_size\n",
    "        batch_end=batch_begin+batch_size\n",
    "        \n",
    "        pretrain_fns=[]\n",
    "        for layer_i,dA in enumerate(self.dA_layers):\n",
    "            print('pretraining layer %d functions built.'%layer_i)\n",
    "            # get the cost and the updates list\n",
    "            cost, updates = dA.get_cost_updates(corruption_level,\n",
    "                                                learning_rate)\n",
    "            # compile the theano function\n",
    "            fn = theano.function(\n",
    "                inputs=[\n",
    "                    index,\n",
    "                    theano.In(corruption_level, value=0.2),\n",
    "                    theano.In(learning_rate, value=0.1)\n",
    "                ],\n",
    "                outputs=cost,\n",
    "                updates=updates,\n",
    "                givens={\n",
    "                    self.x: train_set_x[batch_begin: batch_end]\n",
    "                }\n",
    "            )\n",
    "            # append `fn` to the list of functions\n",
    "            pretrain_fns.append(fn)\n",
    "\n",
    "        return pretrain_fns\n",
    "\n",
    "    def build_finetune_functions(self, datasets, batch_size, learning_rate):\n",
    "        '''Generates a function `train` that implements one step of\n",
    "        finetuning, a function `validate` that computes the error on\n",
    "        a batch from the validation set, and a function `test` that\n",
    "        computes the error on a batch from the testing set\n",
    "        '''\n",
    "\n",
    "        (train_set_x, train_set_y) = datasets[0]\n",
    "        (valid_set_x, valid_set_y) = datasets[1]\n",
    "        (test_set_x, test_set_y) = datasets[2]\n",
    "        \n",
    "        # compute number of minibatches for training, validation and testing\n",
    "        n_valid_batches = valid_set_x.get_value(borrow=True).shape[0]\n",
    "        n_valid_batches //= batch_size\n",
    "        n_test_batches = test_set_x.get_value(borrow=True).shape[0]\n",
    "        n_test_batches //= batch_size\n",
    "\n",
    "        index = T.lscalar('index')  # index to a [mini]batch\n",
    "\n",
    "        # compute the gradients with respect to the model parameters\n",
    "        gparams = T.grad(self.finetune_cost, self.params)\n",
    "\n",
    "        # compute list of fine-tuning updates\n",
    "        updates = [ (param, param - gparam * learning_rate)\n",
    "            for param, gparam in zip(self.params, gparams) ]\n",
    "\n",
    "        train_fn = theano.function(\n",
    "            inputs=[index],\n",
    "            outputs=self.finetune_cost,\n",
    "            updates=updates,\n",
    "            givens={\n",
    "                self.x: train_set_x[\n",
    "                    index * batch_size: (index + 1) * batch_size\n",
    "                ],\n",
    "                self.y: train_set_y[\n",
    "                    index * batch_size: (index + 1) * batch_size\n",
    "                ]\n",
    "            },\n",
    "            name='train'\n",
    "        )\n",
    "\n",
    "        test_score_i = theano.function(\n",
    "            [index],\n",
    "            self.errors,\n",
    "            givens={\n",
    "                self.x: test_set_x[\n",
    "                    index * batch_size: (index + 1) * batch_size\n",
    "                ],\n",
    "                self.y: test_set_y[\n",
    "                    index * batch_size: (index + 1) * batch_size\n",
    "                ]\n",
    "            },\n",
    "            name='test'\n",
    "        )\n",
    "\n",
    "        valid_score_i = theano.function(\n",
    "            [index],\n",
    "            self.errors,\n",
    "            givens={\n",
    "                self.x: valid_set_x[\n",
    "                    index * batch_size: (index + 1) * batch_size\n",
    "                ],\n",
    "                self.y: valid_set_y[\n",
    "                    index * batch_size: (index + 1) * batch_size\n",
    "                ]\n",
    "            },\n",
    "            name='valid'\n",
    "        )\n",
    "\n",
    "        # Create a function that scans the entire validation set\n",
    "        def valid_score():\n",
    "            return [valid_score_i(i) for i in range(n_valid_batches)]\n",
    "\n",
    "        # Create a function that scans the entire test set\n",
    "        def test_score():\n",
    "            return [test_score_i(i) for i in range(n_test_batches)]\n",
    "\n",
    "        return train_fn, valid_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... building the model\n",
      "... getting the pretraining functions\n",
      "pretraining layer 0 functions built.\n",
      "pretraining layer 1 functions built.\n",
      "pretraining layer 2 functions built.\n",
      "... pre-training the model\n",
      "  Pre-training layer 0, epoch 0, batch 0\n",
      "Pre-training layer 0, epoch 0, cost 123.402131\n",
      "  Pre-training layer 0, epoch 1, batch 0\n",
      "Pre-training layer 0, epoch 1, cost 95.798796\n",
      "  Pre-training layer 0, epoch 2, batch 0\n",
      "Pre-training layer 0, epoch 2, cost 89.016028\n",
      "  Pre-training layer 0, epoch 3, batch 0\n",
      "Pre-training layer 0, epoch 3, cost 84.920240\n",
      "  Pre-training layer 0, epoch 4, batch 0\n",
      "Pre-training layer 0, epoch 4, cost 82.094254\n",
      "  Pre-training layer 0, epoch 5, batch 0\n",
      "Pre-training layer 0, epoch 5, cost 79.984921\n",
      "  Pre-training layer 0, epoch 6, batch 0\n",
      "Pre-training layer 0, epoch 6, cost 78.310323\n",
      "  Pre-training layer 0, epoch 7, batch 0\n",
      "Pre-training layer 0, epoch 7, cost 76.930004\n",
      "  Pre-training layer 0, epoch 8, batch 0\n",
      "Pre-training layer 0, epoch 8, cost 75.751763\n",
      "  Pre-training layer 0, epoch 9, batch 0\n",
      "Pre-training layer 0, epoch 9, cost 74.778716\n",
      "  Pre-training layer 1, epoch 0, batch 0\n",
      "Pre-training layer 1, epoch 0, cost 589.930298\n",
      "  Pre-training layer 1, epoch 1, batch 0\n",
      "Pre-training layer 1, epoch 1, cost 555.939082\n",
      "  Pre-training layer 1, epoch 2, batch 0\n",
      "Pre-training layer 1, epoch 2, cost 544.547527\n",
      "  Pre-training layer 1, epoch 3, batch 0\n",
      "Pre-training layer 1, epoch 3, cost 537.988113\n",
      "  Pre-training layer 1, epoch 4, batch 0\n",
      "Pre-training layer 1, epoch 4, cost 533.453740\n",
      "  Pre-training layer 1, epoch 5, batch 0\n",
      "Pre-training layer 1, epoch 5, cost 530.025144\n",
      "  Pre-training layer 1, epoch 6, batch 0\n",
      "Pre-training layer 1, epoch 6, cost 527.361566\n",
      "  Pre-training layer 1, epoch 7, batch 0\n",
      "Pre-training layer 1, epoch 7, cost 525.163602\n",
      "  Pre-training layer 1, epoch 8, batch 0\n",
      "Pre-training layer 1, epoch 8, cost 523.315215\n",
      "  Pre-training layer 1, epoch 9, batch 0\n",
      "Pre-training layer 1, epoch 9, cost 521.722885\n",
      "  Pre-training layer 2, epoch 0, batch 0\n",
      "Pre-training layer 2, epoch 0, cost 298.269299\n",
      "  Pre-training layer 2, epoch 1, batch 0\n",
      "Pre-training layer 2, epoch 1, cost 270.601837\n",
      "  Pre-training layer 2, epoch 2, batch 0\n",
      "Pre-training layer 2, epoch 2, cost 261.594732\n",
      "  Pre-training layer 2, epoch 3, batch 0\n",
      "Pre-training layer 2, epoch 3, cost 256.200694\n",
      "  Pre-training layer 2, epoch 4, batch 0\n",
      "Pre-training layer 2, epoch 4, cost 252.532788\n",
      "  Pre-training layer 2, epoch 5, batch 0\n",
      "Pre-training layer 2, epoch 5, cost 249.836851\n",
      "  Pre-training layer 2, epoch 6, batch 0\n",
      "Pre-training layer 2, epoch 6, cost 247.759328\n",
      "  Pre-training layer 2, epoch 7, batch 0\n",
      "Pre-training layer 2, epoch 7, cost 246.087643\n",
      "  Pre-training layer 2, epoch 8, batch 0\n",
      "Pre-training layer 2, epoch 8, cost 244.708944\n",
      "  Pre-training layer 2, epoch 9, batch 0\n",
      "Pre-training layer 2, epoch 9, cost 243.553883\n",
      "... getting the finetuning functions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The pretraining code for file __file__ ran for 20.05m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... finetunning the model\n",
      "epoch 1, minibatch 1000/1000, validation error 8.190000 %\n",
      "     epoch 1, minibatch 1000/1000, test error of best model 9.070000 %\n",
      "epoch 2, minibatch 1000/1000, validation error 6.180000 %\n",
      "     epoch 2, minibatch 1000/1000, test error of best model 6.940000 %\n",
      "epoch 3, minibatch 1000/1000, validation error 5.090000 %\n",
      "     epoch 3, minibatch 1000/1000, test error of best model 5.740000 %\n",
      "epoch 4, minibatch 1000/1000, validation error 4.470000 %\n",
      "     epoch 4, minibatch 1000/1000, test error of best model 5.100000 %\n",
      "epoch 5, minibatch 1000/1000, validation error 4.040000 %\n",
      "     epoch 5, minibatch 1000/1000, test error of best model 4.620000 %\n",
      "epoch 6, minibatch 1000/1000, validation error 3.710000 %\n",
      "     epoch 6, minibatch 1000/1000, test error of best model 4.220000 %\n",
      "epoch 7, minibatch 1000/1000, validation error 3.520000 %\n",
      "     epoch 7, minibatch 1000/1000, test error of best model 3.970000 %\n",
      "epoch 8, minibatch 1000/1000, validation error 3.360000 %\n",
      "     epoch 8, minibatch 1000/1000, test error of best model 3.710000 %\n",
      "epoch 9, minibatch 1000/1000, validation error 3.170000 %\n",
      "     epoch 9, minibatch 1000/1000, test error of best model 3.510000 %\n",
      "epoch 10, minibatch 1000/1000, validation error 3.080000 %\n",
      "     epoch 10, minibatch 1000/1000, test error of best model 3.440000 %\n",
      "epoch 11, minibatch 1000/1000, validation error 2.960000 %\n",
      "     epoch 11, minibatch 1000/1000, test error of best model 3.280000 %\n",
      "epoch 12, minibatch 1000/1000, validation error 2.800000 %\n",
      "     epoch 12, minibatch 1000/1000, test error of best model 3.160000 %\n",
      "epoch 13, minibatch 1000/1000, validation error 2.730000 %\n",
      "     epoch 13, minibatch 1000/1000, test error of best model 3.050000 %\n",
      "epoch 14, minibatch 1000/1000, validation error 2.650000 %\n",
      "     epoch 14, minibatch 1000/1000, test error of best model 2.960000 %\n",
      "epoch 15, minibatch 1000/1000, validation error 2.630000 %\n",
      "     epoch 15, minibatch 1000/1000, test error of best model 2.900000 %\n",
      "epoch 16, minibatch 1000/1000, validation error 2.570000 %\n",
      "     epoch 16, minibatch 1000/1000, test error of best model 2.800000 %\n",
      "epoch 17, minibatch 1000/1000, validation error 2.530000 %\n",
      "     epoch 17, minibatch 1000/1000, test error of best model 2.750000 %\n",
      "epoch 18, minibatch 1000/1000, validation error 2.500000 %\n",
      "     epoch 18, minibatch 1000/1000, test error of best model 2.710000 %\n",
      "epoch 19, minibatch 1000/1000, validation error 2.390000 %\n",
      "     epoch 19, minibatch 1000/1000, test error of best model 2.610000 %\n",
      "epoch 20, minibatch 1000/1000, validation error 2.350000 %\n",
      "     epoch 20, minibatch 1000/1000, test error of best model 2.540000 %\n",
      "epoch 21, minibatch 1000/1000, validation error 2.300000 %\n",
      "     epoch 21, minibatch 1000/1000, test error of best model 2.520000 %\n",
      "epoch 22, minibatch 1000/1000, validation error 2.320000 %\n",
      "epoch 23, minibatch 1000/1000, validation error 2.280000 %\n",
      "     epoch 23, minibatch 1000/1000, test error of best model 2.350000 %\n",
      "epoch 24, minibatch 1000/1000, validation error 2.260000 %\n",
      "     epoch 24, minibatch 1000/1000, test error of best model 2.340000 %\n",
      "epoch 25, minibatch 1000/1000, validation error 2.230000 %\n",
      "     epoch 25, minibatch 1000/1000, test error of best model 2.280000 %\n",
      "epoch 26, minibatch 1000/1000, validation error 2.190000 %\n",
      "     epoch 26, minibatch 1000/1000, test error of best model 2.260000 %\n",
      "epoch 27, minibatch 1000/1000, validation error 2.180000 %\n",
      "     epoch 27, minibatch 1000/1000, test error of best model 2.240000 %\n",
      "epoch 28, minibatch 1000/1000, validation error 2.130000 %\n",
      "     epoch 28, minibatch 1000/1000, test error of best model 2.200000 %\n",
      "epoch 29, minibatch 1000/1000, validation error 2.120000 %\n",
      "     epoch 29, minibatch 1000/1000, test error of best model 2.170000 %\n",
      "epoch 30, minibatch 1000/1000, validation error 2.090000 %\n",
      "     epoch 30, minibatch 1000/1000, test error of best model 2.150000 %\n",
      "epoch 31, minibatch 1000/1000, validation error 2.070000 %\n",
      "     epoch 31, minibatch 1000/1000, test error of best model 2.110000 %\n",
      "epoch 32, minibatch 1000/1000, validation error 2.040000 %\n",
      "     epoch 32, minibatch 1000/1000, test error of best model 2.110000 %\n",
      "epoch 33, minibatch 1000/1000, validation error 2.030000 %\n",
      "     epoch 33, minibatch 1000/1000, test error of best model 2.080000 %\n",
      "epoch 34, minibatch 1000/1000, validation error 2.010000 %\n",
      "     epoch 34, minibatch 1000/1000, test error of best model 2.080000 %\n",
      "epoch 35, minibatch 1000/1000, validation error 1.990000 %\n",
      "     epoch 35, minibatch 1000/1000, test error of best model 2.100000 %\n",
      "epoch 36, minibatch 1000/1000, validation error 1.970000 %\n",
      "     epoch 36, minibatch 1000/1000, test error of best model 2.120000 %\n",
      "epoch 37, minibatch 1000/1000, validation error 1.970000 %\n",
      "epoch 38, minibatch 1000/1000, validation error 1.960000 %\n",
      "     epoch 38, minibatch 1000/1000, test error of best model 2.100000 %\n",
      "epoch 39, minibatch 1000/1000, validation error 1.930000 %\n",
      "     epoch 39, minibatch 1000/1000, test error of best model 2.080000 %\n",
      "epoch 40, minibatch 1000/1000, validation error 1.920000 %\n",
      "     epoch 40, minibatch 1000/1000, test error of best model 2.070000 %\n",
      "epoch 41, minibatch 1000/1000, validation error 1.900000 %\n",
      "     epoch 41, minibatch 1000/1000, test error of best model 2.080000 %\n",
      "epoch 42, minibatch 1000/1000, validation error 1.890000 %\n",
      "     epoch 42, minibatch 1000/1000, test error of best model 2.050000 %\n",
      "epoch 43, minibatch 1000/1000, validation error 1.890000 %\n",
      "epoch 44, minibatch 1000/1000, validation error 1.900000 %\n",
      "epoch 45, minibatch 1000/1000, validation error 1.910000 %\n",
      "epoch 46, minibatch 1000/1000, validation error 1.910000 %\n",
      "epoch 47, minibatch 1000/1000, validation error 1.920000 %\n",
      "epoch 48, minibatch 1000/1000, validation error 1.890000 %\n",
      "epoch 49, minibatch 1000/1000, validation error 1.890000 %\n",
      "epoch 50, minibatch 1000/1000, validation error 1.880000 %\n",
      "     epoch 50, minibatch 1000/1000, test error of best model 1.910000 %\n",
      "epoch 51, minibatch 1000/1000, validation error 1.860000 %\n",
      "     epoch 51, minibatch 1000/1000, test error of best model 1.890000 %\n",
      "epoch 52, minibatch 1000/1000, validation error 1.880000 %\n",
      "epoch 53, minibatch 1000/1000, validation error 1.900000 %\n",
      "epoch 54, minibatch 1000/1000, validation error 1.910000 %\n",
      "epoch 55, minibatch 1000/1000, validation error 1.900000 %\n",
      "epoch 56, minibatch 1000/1000, validation error 1.880000 %\n",
      "epoch 57, minibatch 1000/1000, validation error 1.900000 %\n",
      "epoch 58, minibatch 1000/1000, validation error 1.900000 %\n",
      "epoch 59, minibatch 1000/1000, validation error 1.900000 %\n",
      "epoch 60, minibatch 1000/1000, validation error 1.900000 %\n",
      "epoch 61, minibatch 1000/1000, validation error 1.890000 %\n",
      "epoch 62, minibatch 1000/1000, validation error 1.900000 %\n",
      "epoch 63, minibatch 1000/1000, validation error 1.880000 %\n",
      "epoch 64, minibatch 1000/1000, validation error 1.880000 %\n",
      "epoch 65, minibatch 1000/1000, validation error 1.880000 %\n",
      "epoch 66, minibatch 1000/1000, validation error 1.880000 %\n",
      "epoch 67, minibatch 1000/1000, validation error 1.860000 %\n",
      "epoch 68, minibatch 1000/1000, validation error 1.840000 %\n",
      "     epoch 68, minibatch 1000/1000, test error of best model 1.840000 %\n",
      "epoch 69, minibatch 1000/1000, validation error 1.840000 %\n",
      "epoch 70, minibatch 1000/1000, validation error 1.850000 %\n",
      "epoch 71, minibatch 1000/1000, validation error 1.860000 %\n",
      "epoch 72, minibatch 1000/1000, validation error 1.850000 %\n",
      "epoch 73, minibatch 1000/1000, validation error 1.840000 %\n",
      "epoch 74, minibatch 1000/1000, validation error 1.830000 %\n",
      "     epoch 74, minibatch 1000/1000, test error of best model 1.810000 %\n",
      "epoch 75, minibatch 1000/1000, validation error 1.830000 %\n",
      "epoch 76, minibatch 1000/1000, validation error 1.840000 %\n",
      "epoch 77, minibatch 1000/1000, validation error 1.840000 %\n",
      "epoch 78, minibatch 1000/1000, validation error 1.840000 %\n",
      "epoch 79, minibatch 1000/1000, validation error 1.840000 %\n",
      "epoch 80, minibatch 1000/1000, validation error 1.830000 %\n",
      "epoch 81, minibatch 1000/1000, validation error 1.820000 %\n",
      "     epoch 81, minibatch 1000/1000, test error of best model 1.770000 %\n",
      "epoch 82, minibatch 1000/1000, validation error 1.810000 %\n",
      "     epoch 82, minibatch 1000/1000, test error of best model 1.770000 %\n",
      "epoch 83, minibatch 1000/1000, validation error 1.800000 %\n",
      "     epoch 83, minibatch 1000/1000, test error of best model 1.770000 %\n",
      "epoch 84, minibatch 1000/1000, validation error 1.810000 %\n",
      "epoch 85, minibatch 1000/1000, validation error 1.800000 %\n",
      "     epoch 85, minibatch 1000/1000, test error of best model 1.760000 %\n",
      "epoch 86, minibatch 1000/1000, validation error 1.810000 %\n",
      "epoch 87, minibatch 1000/1000, validation error 1.800000 %\n",
      "epoch 88, minibatch 1000/1000, validation error 1.790000 %\n",
      "     epoch 88, minibatch 1000/1000, test error of best model 1.770000 %\n",
      "epoch 89, minibatch 1000/1000, validation error 1.790000 %\n",
      "epoch 90, minibatch 1000/1000, validation error 1.790000 %\n",
      "epoch 91, minibatch 1000/1000, validation error 1.810000 %\n",
      "epoch 92, minibatch 1000/1000, validation error 1.820000 %\n",
      "epoch 93, minibatch 1000/1000, validation error 1.820000 %\n",
      "epoch 94, minibatch 1000/1000, validation error 1.820000 %\n",
      "epoch 95, minibatch 1000/1000, validation error 1.830000 %\n",
      "epoch 96, minibatch 1000/1000, validation error 1.820000 %\n",
      "epoch 97, minibatch 1000/1000, validation error 1.820000 %\n",
      "epoch 98, minibatch 1000/1000, validation error 1.820000 %\n",
      "epoch 99, minibatch 1000/1000, validation error 1.810000 %\n",
      "epoch 100, minibatch 1000/1000, validation error 1.810000 %\n",
      "epoch 101, minibatch 1000/1000, validation error 1.810000 %\n",
      "epoch 102, minibatch 1000/1000, validation error 1.810000 %\n",
      "epoch 103, minibatch 1000/1000, validation error 1.800000 %\n",
      "epoch 104, minibatch 1000/1000, validation error 1.800000 %\n",
      "epoch 105, minibatch 1000/1000, validation error 1.810000 %\n",
      "epoch 106, minibatch 1000/1000, validation error 1.810000 %\n",
      "epoch 107, minibatch 1000/1000, validation error 1.800000 %\n",
      "epoch 108, minibatch 1000/1000, validation error 1.800000 %\n",
      "epoch 109, minibatch 1000/1000, validation error 1.800000 %\n",
      "epoch 110, minibatch 1000/1000, validation error 1.800000 %\n",
      "epoch 111, minibatch 1000/1000, validation error 1.800000 %\n",
      "epoch 112, minibatch 1000/1000, validation error 1.800000 %\n",
      "epoch 113, minibatch 1000/1000, validation error 1.800000 %\n",
      "epoch 114, minibatch 1000/1000, validation error 1.800000 %\n",
      "epoch 115, minibatch 1000/1000, validation error 1.820000 %\n",
      "epoch 116, minibatch 1000/1000, validation error 1.820000 %\n",
      "epoch 117, minibatch 1000/1000, validation error 1.820000 %\n",
      "epoch 118, minibatch 1000/1000, validation error 1.820000 %\n",
      "epoch 119, minibatch 1000/1000, validation error 1.820000 %\n",
      "epoch 120, minibatch 1000/1000, validation error 1.820000 %\n",
      "epoch 121, minibatch 1000/1000, validation error 1.820000 %\n",
      "epoch 122, minibatch 1000/1000, validation error 1.830000 %\n",
      "epoch 123, minibatch 1000/1000, validation error 1.840000 %\n",
      "epoch 124, minibatch 1000/1000, validation error 1.840000 %\n",
      "epoch 125, minibatch 1000/1000, validation error 1.830000 %\n",
      "epoch 126, minibatch 1000/1000, validation error 1.820000 %\n",
      "epoch 127, minibatch 1000/1000, validation error 1.820000 %\n",
      "epoch 128, minibatch 1000/1000, validation error 1.820000 %\n",
      "epoch 129, minibatch 1000/1000, validation error 1.830000 %\n",
      "epoch 130, minibatch 1000/1000, validation error 1.830000 %\n",
      "epoch 131, minibatch 1000/1000, validation error 1.830000 %\n",
      "epoch 132, minibatch 1000/1000, validation error 1.830000 %\n",
      "epoch 133, minibatch 1000/1000, validation error 1.830000 %\n",
      "epoch 134, minibatch 1000/1000, validation error 1.830000 %\n",
      "epoch 135, minibatch 1000/1000, validation error 1.830000 %\n",
      "epoch 136, minibatch 1000/1000, validation error 1.830000 %\n",
      "epoch 137, minibatch 1000/1000, validation error 1.830000 %\n",
      "epoch 138, minibatch 1000/1000, validation error 1.830000 %\n",
      "epoch 139, minibatch 1000/1000, validation error 1.830000 %\n",
      "epoch 140, minibatch 1000/1000, validation error 1.830000 %\n",
      "epoch 141, minibatch 1000/1000, validation error 1.830000 %\n",
      "epoch 142, minibatch 1000/1000, validation error 1.830000 %\n",
      "epoch 143, minibatch 1000/1000, validation error 1.830000 %\n",
      "epoch 144, minibatch 1000/1000, validation error 1.820000 %\n",
      "epoch 145, minibatch 1000/1000, validation error 1.810000 %\n",
      "epoch 146, minibatch 1000/1000, validation error 1.810000 %\n",
      "epoch 147, minibatch 1000/1000, validation error 1.810000 %\n",
      "epoch 148, minibatch 1000/1000, validation error 1.810000 %\n",
      "epoch 149, minibatch 1000/1000, validation error 1.810000 %\n",
      "epoch 150, minibatch 1000/1000, validation error 1.810000 %\n",
      "epoch 151, minibatch 1000/1000, validation error 1.810000 %\n",
      "epoch 152, minibatch 1000/1000, validation error 1.810000 %\n",
      "epoch 153, minibatch 1000/1000, validation error 1.810000 %\n",
      "epoch 154, minibatch 1000/1000, validation error 1.810000 %\n",
      "epoch 155, minibatch 1000/1000, validation error 1.810000 %\n",
      "epoch 156, minibatch 1000/1000, validation error 1.810000 %\n",
      "epoch 157, minibatch 1000/1000, validation error 1.810000 %\n",
      "epoch 158, minibatch 1000/1000, validation error 1.810000 %\n",
      "epoch 159, minibatch 1000/1000, validation error 1.810000 %\n",
      "epoch 160, minibatch 1000/1000, validation error 1.810000 %\n",
      "epoch 161, minibatch 1000/1000, validation error 1.810000 %\n",
      "epoch 162, minibatch 1000/1000, validation error 1.810000 %\n",
      "epoch 163, minibatch 1000/1000, validation error 1.810000 %\n",
      "epoch 164, minibatch 1000/1000, validation error 1.810000 %\n",
      "epoch 165, minibatch 1000/1000, validation error 1.800000 %\n",
      "epoch 166, minibatch 1000/1000, validation error 1.800000 %\n",
      "epoch 167, minibatch 1000/1000, validation error 1.800000 %\n",
      "epoch 168, minibatch 1000/1000, validation error 1.790000 %\n",
      "epoch 169, minibatch 1000/1000, validation error 1.790000 %\n",
      "epoch 170, minibatch 1000/1000, validation error 1.790000 %\n",
      "epoch 171, minibatch 1000/1000, validation error 1.790000 %\n",
      "epoch 172, minibatch 1000/1000, validation error 1.790000 %\n",
      "epoch 173, minibatch 1000/1000, validation error 1.790000 %\n",
      "epoch 174, minibatch 1000/1000, validation error 1.790000 %\n",
      "epoch 175, minibatch 1000/1000, validation error 1.780000 %\n",
      "     epoch 175, minibatch 1000/1000, test error of best model 1.690000 %\n",
      "epoch 176, minibatch 1000/1000, validation error 1.780000 %\n",
      "epoch 177, minibatch 1000/1000, validation error 1.780000 %\n",
      "epoch 178, minibatch 1000/1000, validation error 1.780000 %\n",
      "epoch 179, minibatch 1000/1000, validation error 1.780000 %\n",
      "epoch 180, minibatch 1000/1000, validation error 1.780000 %\n",
      "epoch 181, minibatch 1000/1000, validation error 1.780000 %\n",
      "epoch 182, minibatch 1000/1000, validation error 1.780000 %\n",
      "epoch 183, minibatch 1000/1000, validation error 1.780000 %\n",
      "epoch 184, minibatch 1000/1000, validation error 1.780000 %\n",
      "epoch 185, minibatch 1000/1000, validation error 1.780000 %\n",
      "epoch 186, minibatch 1000/1000, validation error 1.780000 %\n",
      "epoch 187, minibatch 1000/1000, validation error 1.780000 %\n",
      "epoch 188, minibatch 1000/1000, validation error 1.780000 %\n",
      "epoch 189, minibatch 1000/1000, validation error 1.780000 %\n",
      "epoch 190, minibatch 1000/1000, validation error 1.780000 %\n",
      "epoch 191, minibatch 1000/1000, validation error 1.780000 %\n",
      "epoch 192, minibatch 1000/1000, validation error 1.780000 %\n",
      "epoch 193, minibatch 1000/1000, validation error 1.780000 %\n",
      "epoch 194, minibatch 1000/1000, validation error 1.770000 %\n",
      "     epoch 194, minibatch 1000/1000, test error of best model 1.680000 %\n",
      "epoch 195, minibatch 1000/1000, validation error 1.770000 %\n",
      "epoch 196, minibatch 1000/1000, validation error 1.770000 %\n",
      "epoch 197, minibatch 1000/1000, validation error 1.770000 %\n",
      "epoch 198, minibatch 1000/1000, validation error 1.770000 %\n",
      "epoch 199, minibatch 1000/1000, validation error 1.770000 %\n",
      "epoch 200, minibatch 1000/1000, validation error 1.770000 %\n",
      "epoch 201, minibatch 1000/1000, validation error 1.770000 %\n",
      "epoch 202, minibatch 1000/1000, validation error 1.770000 %\n",
      "epoch 203, minibatch 1000/1000, validation error 1.770000 %\n",
      "epoch 204, minibatch 1000/1000, validation error 1.770000 %\n",
      "epoch 205, minibatch 1000/1000, validation error 1.770000 %\n",
      "epoch 206, minibatch 1000/1000, validation error 1.760000 %\n",
      "     epoch 206, minibatch 1000/1000, test error of best model 1.680000 %\n",
      "epoch 207, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 208, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 209, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 210, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 211, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 212, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 213, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 214, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 215, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 216, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 217, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 218, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 219, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 220, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 221, minibatch 1000/1000, validation error 1.750000 %\n",
      "     epoch 221, minibatch 1000/1000, test error of best model 1.710000 %\n",
      "epoch 222, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 223, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 224, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 225, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 226, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 227, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 228, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 229, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 230, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 231, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 232, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 233, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 234, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 235, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 236, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 237, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 238, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 239, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 240, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 241, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 242, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 243, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 244, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 245, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 246, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 247, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 248, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 249, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 250, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 251, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 252, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 253, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 254, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 255, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 256, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 257, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 258, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 259, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 260, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 261, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 262, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 263, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 264, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 265, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 266, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 267, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 268, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 269, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 270, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 271, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 272, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 273, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 274, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 275, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 276, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 277, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 278, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 279, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 280, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 281, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 282, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 283, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 284, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 285, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 286, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 287, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 288, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 289, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 290, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 291, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 292, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 293, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 294, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 295, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 296, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 297, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 298, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 299, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 300, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 301, minibatch 1000/1000, validation error 1.740000 %\n",
      "     epoch 301, minibatch 1000/1000, test error of best model 1.690000 %\n",
      "epoch 302, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 303, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 304, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 305, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 306, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 307, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 308, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 309, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 310, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 311, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 312, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 313, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 314, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 315, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 316, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 317, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 318, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 319, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 320, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 321, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 322, minibatch 1000/1000, validation error 1.730000 %\n",
      "     epoch 322, minibatch 1000/1000, test error of best model 1.700000 %\n",
      "epoch 323, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 324, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 325, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 326, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 327, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 328, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 329, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 330, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 331, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 332, minibatch 1000/1000, validation error 1.720000 %\n",
      "     epoch 332, minibatch 1000/1000, test error of best model 1.690000 %\n",
      "epoch 333, minibatch 1000/1000, validation error 1.720000 %\n",
      "epoch 334, minibatch 1000/1000, validation error 1.720000 %\n",
      "epoch 335, minibatch 1000/1000, validation error 1.720000 %\n",
      "epoch 336, minibatch 1000/1000, validation error 1.720000 %\n",
      "epoch 337, minibatch 1000/1000, validation error 1.720000 %\n",
      "epoch 338, minibatch 1000/1000, validation error 1.720000 %\n",
      "epoch 339, minibatch 1000/1000, validation error 1.720000 %\n",
      "epoch 340, minibatch 1000/1000, validation error 1.720000 %\n",
      "epoch 341, minibatch 1000/1000, validation error 1.720000 %\n",
      "epoch 342, minibatch 1000/1000, validation error 1.720000 %\n",
      "epoch 343, minibatch 1000/1000, validation error 1.720000 %\n",
      "epoch 344, minibatch 1000/1000, validation error 1.720000 %\n",
      "epoch 345, minibatch 1000/1000, validation error 1.720000 %\n",
      "epoch 346, minibatch 1000/1000, validation error 1.720000 %\n",
      "epoch 347, minibatch 1000/1000, validation error 1.720000 %\n",
      "epoch 348, minibatch 1000/1000, validation error 1.720000 %\n",
      "epoch 349, minibatch 1000/1000, validation error 1.720000 %\n",
      "epoch 350, minibatch 1000/1000, validation error 1.720000 %\n",
      "epoch 351, minibatch 1000/1000, validation error 1.720000 %\n",
      "epoch 352, minibatch 1000/1000, validation error 1.720000 %\n",
      "epoch 353, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 354, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 355, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 356, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 357, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 358, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 359, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 360, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 361, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 362, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 363, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 364, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 365, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 366, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 367, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 368, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 369, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 370, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 371, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 372, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 373, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 374, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 375, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 376, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 377, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 378, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 379, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 380, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 381, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 382, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 383, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 384, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 385, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 386, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 387, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 388, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 389, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 390, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 391, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 392, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 393, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 394, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 395, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 396, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 397, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 398, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 399, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 400, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 401, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 402, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 403, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 404, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 405, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 406, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 407, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 408, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 409, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 410, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 411, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 412, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 413, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 414, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 415, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 416, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 417, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 418, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 419, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 420, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 421, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 422, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 423, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 424, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 425, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 426, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 427, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 428, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 429, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 430, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 431, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 432, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 433, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 434, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 435, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 436, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 437, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 438, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 439, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 440, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 441, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 442, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 443, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 444, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 445, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 446, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 447, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 448, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 449, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 450, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 451, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 452, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 453, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 454, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 455, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 456, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 457, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 458, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 459, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 460, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 461, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 462, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 463, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 464, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 465, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 466, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 467, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 468, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 469, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 470, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 471, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 472, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 473, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 474, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 475, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 476, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 477, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 478, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 479, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 480, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 481, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 482, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 483, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 484, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 485, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 486, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 487, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 488, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 489, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 490, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 491, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 492, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 493, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 494, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 495, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 496, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 497, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 498, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 499, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 500, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 501, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 502, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 503, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 504, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 505, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 506, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 507, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 508, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 509, minibatch 1000/1000, validation error 1.730000 %\n",
      "epoch 510, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 511, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 512, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 513, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 514, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 515, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 516, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 517, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 518, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 519, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 520, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 521, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 522, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 523, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 524, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 525, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 526, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 527, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 528, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 529, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 530, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 531, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 532, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 533, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 534, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 535, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 536, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 537, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 538, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 539, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 540, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 541, minibatch 1000/1000, validation error 1.740000 %\n",
      "epoch 542, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 543, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 544, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 545, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 546, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 547, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 548, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 549, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 550, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 551, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 552, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 553, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 554, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 555, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 556, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 557, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 558, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 559, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 560, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 561, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 562, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 563, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 564, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 565, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 566, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 567, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 568, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 569, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 570, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 571, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 572, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 573, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 574, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 575, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 576, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 577, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 578, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 579, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 580, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 581, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 582, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 583, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 584, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 585, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 586, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 587, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 588, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 589, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 590, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 591, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 592, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 593, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 594, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 595, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 596, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 597, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 598, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 599, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 600, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 601, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 602, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 603, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 604, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 605, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 606, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 607, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 608, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 609, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 610, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 611, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 612, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 613, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 614, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 615, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 616, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 617, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 618, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 619, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 620, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 621, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 622, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 623, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 624, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 625, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 626, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 627, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 628, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 629, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 630, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 631, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 632, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 633, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 634, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 635, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 636, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 637, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 638, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 639, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 640, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 641, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 642, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 643, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 644, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 645, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 646, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 647, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 648, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 649, minibatch 1000/1000, validation error 1.750000 %\n",
      "epoch 650, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 651, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 652, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 653, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 654, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 655, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 656, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 657, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 658, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 659, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 660, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 661, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 662, minibatch 1000/1000, validation error 1.760000 %\n",
      "epoch 663, minibatch 1000/1000, validation error 1.760000 %\n",
      "Optimization complete with best validation score of 1.720000 %, on iteration 332000, with test performance 1.690000 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The training code for file __file__ ran for 515.09m\n"
     ]
    }
   ],
   "source": [
    "def test_SdA(finetune_lr=0.1, pretraining_epochs=15,\n",
    "             pretrain_lr=0.001, training_epochs=1000,\n",
    "             dataset='mnist.pkl.gz', batch_size=1):\n",
    "    datasets = load_data(dataset)\n",
    "\n",
    "    train_set_x, train_set_y = datasets[0]\n",
    "    valid_set_x, valid_set_y = datasets[1]\n",
    "    test_set_x, test_set_y = datasets[2]\n",
    "\n",
    "    # compute number of minibatches for training, validation and testing\n",
    "    n_train_batches = train_set_x.get_value(borrow=True).shape[0]\n",
    "    n_train_batches //= batch_size\n",
    "\n",
    "    # numpy random generator\n",
    "    numpy_rng = numpy.random.RandomState(89677)\n",
    "    print('... building the model')\n",
    "    # construct the stacked denoising autoencoder class\n",
    "    sda = SdA(\n",
    "        numpy_rng=numpy_rng,\n",
    "        n_ins=28 * 28,\n",
    "        hidden_layers_sizes=[1000, 1000, 1000],\n",
    "        n_outs=10\n",
    "    )\n",
    "    \n",
    "    #########################\n",
    "    # PRETRAINING THE MODEL #\n",
    "    #########################\n",
    "    print('... getting the pretraining functions')\n",
    "    pretraining_fns = sda.pretraining_functions(train_set_x=train_set_x,\n",
    "                                                batch_size=batch_size)\n",
    "    \n",
    "\n",
    "    print('... pre-training the model')\n",
    "    start_time = timeit.default_timer()\n",
    "    ## Pre-train layer-wise\n",
    "    corruption_levels = [.1, .2, .3]\n",
    "    for i in range(sda.n_layers):\n",
    "        # go through pretraining epochs for one layer\n",
    "        for epoch in range(pretraining_epochs):\n",
    "            # go through the training set\n",
    "            c = []\n",
    "            for batch_index in range(n_train_batches):\n",
    "                c.append(pretraining_fns[i](index=batch_index,\n",
    "                         corruption=corruption_levels[i],\n",
    "                         lr=pretrain_lr))\n",
    "                if batch_index%10000==0:\n",
    "                    print('  Pre-training layer %i, epoch %d, batch %d'%(i, epoch, batch_index))\n",
    "            print('Pre-training layer %i, epoch %d, cost %f' % (i, epoch, numpy.mean(c)))\n",
    "\n",
    "    end_time = timeit.default_timer()\n",
    "\n",
    "    print(('The pretraining code for file ' +\n",
    "           os.path.split(os.path.realpath('__file__'))[1] +\n",
    "           ' ran for %.2fm' % ((end_time - start_time) / 60.)), file=sys.stderr)\n",
    "    \n",
    "    ########################\n",
    "    # FINETUNING THE MODEL #\n",
    "    ########################\n",
    "\n",
    "    # get the training, validation and testing function for the model\n",
    "    print('... getting the finetuning functions')\n",
    "    train_fn, validate_model, test_model = sda.build_finetune_functions(\n",
    "        datasets=datasets,\n",
    "        batch_size=batch_size,\n",
    "        learning_rate=finetune_lr\n",
    "    )\n",
    "    \n",
    "    print('... finetunning the model')\n",
    "    # early-stopping parameters\n",
    "    patience = 10 * n_train_batches  # look as this many examples regardless\n",
    "    patience_increase = 2.  # wait this much longer when a new best is\n",
    "                            # found\n",
    "    improvement_threshold = 0.995  # a relative improvement of this much is\n",
    "                                   # considered significant\n",
    "    validation_frequency = min(n_train_batches, patience // 2)\n",
    "                                  # go through this many\n",
    "                                  # minibatche before checking the network\n",
    "                                  # on the validation set; in this case we\n",
    "                                  # check every epoch\n",
    "\n",
    "    best_validation_loss = numpy.inf\n",
    "    test_score = 0.\n",
    "    start_time = timeit.default_timer()\n",
    "\n",
    "    done_looping = False\n",
    "    epoch = 0\n",
    "\n",
    "    while (epoch < training_epochs) and (not done_looping):\n",
    "        epoch = epoch + 1\n",
    "        for minibatch_index in range(n_train_batches):\n",
    "            minibatch_avg_cost = train_fn(minibatch_index)\n",
    "            iter = (epoch - 1) * n_train_batches + minibatch_index\n",
    "\n",
    "            if (iter + 1) % validation_frequency == 0:\n",
    "                validation_losses = validate_model()\n",
    "                this_validation_loss = numpy.mean(validation_losses)\n",
    "                print('epoch %i, minibatch %i/%i, validation error %f %%' %\n",
    "                      (epoch, minibatch_index + 1, n_train_batches,\n",
    "                       this_validation_loss * 100.))\n",
    "\n",
    "                # if we got the best validation score until now\n",
    "                if this_validation_loss < best_validation_loss:\n",
    "\n",
    "                    #improve patience if loss improvement is good enough\n",
    "                    if (\n",
    "                        this_validation_loss < best_validation_loss *\n",
    "                        improvement_threshold\n",
    "                    ):\n",
    "                        patience = max(patience, iter * patience_increase)\n",
    "\n",
    "                    # save best validation score and iteration number\n",
    "                    best_validation_loss = this_validation_loss\n",
    "                    best_iter = iter\n",
    "\n",
    "                    # test it on the test set\n",
    "                    test_losses = test_model()\n",
    "                    test_score = numpy.mean(test_losses)\n",
    "                    print(('     epoch %i, minibatch %i/%i, test error of '\n",
    "                           'best model %f %%') %\n",
    "                          (epoch, minibatch_index + 1, n_train_batches,\n",
    "                           test_score * 100.))\n",
    "                    \n",
    "                    with open('best_sda_model.pkl', 'wb') as f:\n",
    "                        pickle.dump(sda, f)\n",
    "\n",
    "            if patience <= iter:\n",
    "                done_looping = True\n",
    "                break\n",
    "\n",
    "    end_time = timeit.default_timer()\n",
    "    print(\n",
    "        (\n",
    "            'Optimization complete with best validation score of %f %%, '\n",
    "            'on iteration %i, '\n",
    "            'with test performance %f %%'\n",
    "        )\n",
    "        % (best_validation_loss * 100., best_iter + 1, test_score * 100.)\n",
    "    )\n",
    "    print(('The training code for file ' +\n",
    "           os.path.split(os.path.realpath('__file__'))[1] +\n",
    "           ' ran for %.2fm' % ((end_time - start_time) / 60.)), file=sys.stderr)\n",
    "    \n",
    "if __name__=='__main__':\n",
    "    test_SdA(pretraining_epochs=10, batch_size=50)\n",
    "    #test_SdA()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "<img src=\"https://www.filepicker.io/api/file/rljyb6zhQDarTk1btPCt\"></img>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
